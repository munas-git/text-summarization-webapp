{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from string import punctuation\n",
    "punctuation = punctuation + '’'\n",
    "from words_synonyms import words_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"The concept of leadership can be traced back to the very beginning of time in the garden of Eden where the first man, Adam had dominion over every living thing in the garden. Since then, kings have begun to appear. In every gathering, a king was appointed at every rally. Leaders were usually appointed from birth or from God’s instruction. In the Middle Ages, leaders were authoritarian, intimidating, fearful, and rare. As a result of the Renaissance, leadership has moved from the kings alone to parliament which consisted of simple men. This left a question, where did the authority come from? Isn't it from God? Jean-Jacques in 1762 made us know Authority comes from people who give up their personal freedom for their safety and security. Anxiety, robbery, murder was the order of the day for leadership in the Middle Ages. Fear and obedience were planted in the hearts of people between 500 AD and 1300 AD.19th and 20th Century Leadership: The Beginning of the Testimony of the Great Leaders That Emerged Leaders such as Abraham Lincoln of the United States, Giuseppe Mazzini of Italy, Kaiser Wilhelm II of Germany. Scholars have begun to pay more attention to leadership as theories were forming. However, in the 21st century, the emergence of information and communication Technology further evolved the concept of leadership as it provided a platform for greater inclusion in leadership, decision making and planning through globalization.\"\n",
    "sample_text_2 = '''Today Apple shared a new report that offers a snapshot of the ways Apple products are empowering people to be at the centre of their health, and acting as an intelligent guardian for their health and safety. Users, developers, medical institutions, and health organisations around the world are using Apple devices, features, and APIs to break down barriers between people and their health information, all while keeping privacy in mind.\n",
    "Apple’s efforts to \n",
    "advance health primarily fall into two categories, which are detailed in two corresponding sections of the report. The first section describes Apple’s focus on personal health and fitness features on Apple Watch and iPhone that offer actionable, science-based insights and help protect users’ health and safety. The second section shares Apple’s work with the medical community to support research and care. Both sections — along with an Extensions and Spotlights section at the report’s end — include a variety of examples of third-party developers, health institutions, and organisations innovating with Apple technology.\n",
    "“We believe passionately that technology can play a role in improving health outcomes and encouraging people to live a healthier day, and we are excited about the many ways users are benefiting from our health and fitness features, and by the ways third-party developers, institutions, and organisations are using Apple technology to advance health and science,” said Jeff Williams, Apple’s chief operating officer. “Our vision for the future is to continue to create science-based technology that equips people with even more information and acts as an intelligent guardian for their health, so they’re no longer passengers on their own health journey. Instead, we want people to be firmly in the driver’s seat with meaningful, actionable insights.”\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarizer():\n",
    "    '''\n",
    "    Class containing functions to clean, format and summarize text\n",
    "    Parameters:\n",
    "    > self : text, type - string\n",
    "    > self : churn_level float specifying percentage of original content to capture\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__ (self, text, churn_level):\n",
    "        self.text = text\n",
    "        self.churn_level = float(churn_level)\n",
    "        self.text_topic = '' # List that will contain string topics.\n",
    "\n",
    "    \n",
    "    def word_sentence_tokenizer(self):\n",
    "        \"\"\" \n",
    "        This function breaks text into word and sentence tokens   \n",
    "        \n",
    "        Parameters:\n",
    "\n",
    "        > self : text, type -string\n",
    "        > self : churn_level float specifying percentage of original content to capture\n",
    "\n",
    "        return:\n",
    "\n",
    "        (sent_tokens, word_tokens) : Tuple containing sentences (sentence tokens) and\n",
    "        texts (text tokens) contained in text provided\n",
    "        \"\"\"\n",
    "\n",
    "        sent_tokens = sent_tokenize(self.text, 'english')\n",
    "        word_tokens = word_tokenize(self.text, 'english')\n",
    "        return(sent_tokens, word_tokens)\n",
    "\n",
    "    \n",
    "    def word_count_vec(self, word_tokens):\n",
    "        '''\n",
    "         This function produces a dictionary containing the normalized scores of each word tokens in a list\n",
    "         \n",
    "         Parameters:\n",
    "         \n",
    "         > word_tokens = [] # List of words\n",
    "         \n",
    "         return:\n",
    "\n",
    "         word_frequency_scores : Dictionary of word tokens and their normalized scores\n",
    "\n",
    "        '''\n",
    "        clean_words = []\n",
    "        word_frequency_scores = {}\n",
    "\n",
    "        # Looping through to calculate word frequencies\n",
    "        for word in word_tokens:\n",
    "            if word.strip().lower() not in stop_words:\n",
    "                if word not in punctuation:\n",
    "                    clean_words.append(word)\n",
    "                    if word not in word_frequency_scores:\n",
    "                        word_frequency_scores[word] = 1\n",
    "                    else:\n",
    "                        word_frequency_scores[word] += 1\n",
    "        \n",
    "        # Looping through to normalize word_frequency_scores using linear / minmax scaler\n",
    "        max_frequency = max(word_frequency_scores.values())\n",
    "        min_frequency = min(word_frequency_scores.values())\n",
    "        for word in word_frequency_scores.keys():\n",
    "            word_frequency_scores[word] = (word_frequency_scores[word] - min_frequency) / (max_frequency - min_frequency)\n",
    "\n",
    "        topic = max(word_frequency_scores, key=word_frequency_scores.get)\n",
    "        self.text_topic += topic\n",
    "        return(word_frequency_scores)\n",
    "    \n",
    "\n",
    "    def sentence_scoring(self, sentence_tokens, word_frequency_scores):\n",
    "        '''\n",
    "        This function calculates scores for each sentence and returns a dictionary containing sentence, score and order.\n",
    "        \n",
    "        Parameters:\n",
    "\n",
    "        > sentence_tokens: List containing sentence tokens\n",
    "        > word_frequency_scores: Dictionary containing word tokens and their (normalized) scores\n",
    "\n",
    "        return:\n",
    "\n",
    "        sentence_scores : Dictionary of sentences and their scores.\n",
    "\n",
    "        '''\n",
    "        sentence_scores = {}\n",
    "        for sentence in sentence_tokens:\n",
    "            for word in word_tokenize(sentence, 'english'):\n",
    "                if word.lower() in word_frequency_scores.keys():\n",
    "                    if sentence not in sentence_scores.keys():\n",
    "                        sentence_scores[sentence] = word_frequency_scores[word.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sentence] += word_frequency_scores[word.lower()]\n",
    "        return(sentence_scores)\n",
    "\n",
    "        \n",
    "    def summary_sorting(self, sentence_scores):\n",
    "        '''\n",
    "        This function selects the top n sentences based on the sentence scores\n",
    "        then organizes the final sentence in asccending order of how they appeared in original text\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "        self:churn_level - percentage of original content to capture\n",
    "        sentence_scores - Dictionary containing sentences and their scores.\n",
    "\n",
    "        return:\n",
    "\n",
    "        final_summary : String of final / formatted summary output.\n",
    "        '''\n",
    "\n",
    "        order_sorted_sentences = []\n",
    "        score_sorted_sentences = []\n",
    "        sentence_score_order_tuples = []\n",
    "\n",
    "        # multiplying churn level by number of sentences then converting to integer \n",
    "        top_n_sentences = int(self.churn_level * len(sentence_scores.keys()))\n",
    "\n",
    "        order = 1\n",
    "        # sort all sentences in descending order of their sentence_score values\n",
    "        for sentence, score in sentence_scores.items():\n",
    "            sentence_score_order_tuples.append((sentence, score, order))\n",
    "            order += 1\n",
    "        score_sorted_sentences = sorted(sentence_score_order_tuples, key=lambda tup: tup[1], reverse=True)\n",
    "        # Slicing from first to top_n_sentences and appending result to produce final summary.\n",
    "        top_n_slice = score_sorted_sentences[0:top_n_sentences]\n",
    "        order_sorted_sentences = sorted(top_n_slice, key=lambda tup: tup[2], reverse=False)\n",
    "        final_summary_list = [sentence[0] for sentence in order_sorted_sentences]\n",
    "        final_sorted_summary_string = ' '.join(final_summary_list)\n",
    "        return(final_sorted_summary_string)\n",
    "\n",
    "\n",
    "def extract_txt(document):\n",
    "    \"\"\"\n",
    "    Function to extract text from .txt file extension document\n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    > Document with file extension .txt\n",
    "    \n",
    "    return:\n",
    "    \n",
    "    full_text_string : String of text contained in the .txt document provided\n",
    "    \"\"\"\n",
    "    with open(document) as text:\n",
    "        full_text_string = text.read().replace(\"\\n\", '')\n",
    "        return(full_text_string)\n",
    "    \n",
    "\n",
    "def string_synonym_swap(text):\n",
    "    \"\"\"\n",
    "    This function converts strings to their synonyms    \n",
    "    It also returns text containing CAPITAL letters or ending with 's', 'ing' , 'ed' as they are,\n",
    "    including some specified texts whose synonyms are relative to how they appear in sentences.\n",
    "\n",
    "    Parameters:\n",
    "    \n",
    "    > text_list : Strings to be converted to synonyms\n",
    "\n",
    "    return:\n",
    "\n",
    "    > test_synonyms : Synonym converted string of text provided. \n",
    "    \"\"\"\n",
    "    synonyms = [] # final list of synonyms with first index\n",
    "    text_list = text.split()\n",
    "    \n",
    "    for text in text_list:\n",
    "        try:\n",
    "            if text.islower() and len(text) >= 3:\n",
    "                synonyms.append(words_synonyms[text])\n",
    "            elif text in stop_words or text in punctuation or len(text) <3:\n",
    "                synonyms.append(words_synonyms[text])\n",
    "            else:\n",
    "                synonyms.append(text)\n",
    "        except Exception:\n",
    "            synonyms.append(text)\n",
    "        \n",
    "        # Loops through each token, checks if the token is a punctuation. if it is not a punctuation, it appends the token with a space before to the string-text body\n",
    "        # if the token is a punctuation, it appens the token to the text body without a space before.\n",
    "        # 'what is that?' will appear as 'what is that ? ' if this for loop didn't exist.\n",
    "        string = ''\n",
    "        for token in synonyms:\n",
    "            if token not in punctuation:\n",
    "                string += ' '+token\n",
    "            else:\n",
    "                string += token \n",
    "    return(string.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topic of this body of text is \"health\". \n",
      "\n",
      "Original text\n",
      "Today Apple shared a new report that offers a snapshot of the ways Apple products are empowering people to be at the centre of their health, and acting as an intelligent guardian for their health and safety. Users, developers, medical institutions, and health organisations around the world are using Apple devices, features, and APIs to break down barriers between people and their health information, all while keeping privacy in mind.\n",
      "Apple’s efforts to \n",
      "advance health primarily fall into two categories, which are detailed in two corresponding sections of the report. The first section describes Apple’s focus on personal health and fitness features on Apple Watch and iPhone that offer actionable, science-based insights and help protect users’ health and safety. The second section shares Apple’s work with the medical community to support research and care. Both sections — along with an Extensions and Spotlights section at the report’s end — include a variety of examples of third-party developers, health institutions, and organisations innovating with Apple technology.\n",
      "“We believe passionately that technology can play a role in improving health outcomes and encouraging people to live a healthier day, and we are excited about the many ways users are benefiting from our health and fitness features, and by the ways third-party developers, institutions, and organisations are using Apple technology to advance health and science,” said Jeff Williams, Apple’s chief operating officer. “Our vision for the future is to continue to create science-based technology that equips people with even more information and acts as an intelligent guardian for their health, so they’re no longer passengers on their own health journey. Instead, we want people to be firmly in the driver’s seat with meaningful, actionable insights.”\n",
      "\n",
      "\n",
      " Length of original text:  1833\n",
      "\n",
      " Proper summay \n",
      "\n",
      "Today Apple revealed a novel report that offers a glimpse of the methods Apple products are empowering individuals to be at the core of their health, and acting as an intelligent guardian for their medical and safety. Users, developers, health care institutions, and medical organisations around the world are using Apple devices, features, and APIs to break down barriers between individuals and their medical information, all while keeping privacy in mind. The first section describes Apple’s focus on personal medical and wellness features on Apple Watch and iPhone that offer actionable, science-based insights and aid protect users’ medical and safety. “We believe passionately that technology can play a part in improving medical results and encouraging individuals to live a healthier day, and we are excited about the many methods users are enjoying from our medical and wellness features, and by the methods third-party developers, institutions, and organisations are using Apple technology to advance medical and science,” said Jeff Williams, Apple’s chief operating officer. “Our vision for the future is to continue to create science-based technology that equips individuals with even more information and acts as an intelligent guardian for their health, so they’re no longer passengers on their own medical journey.\n",
      "length of summary:  1329\n"
     ]
    }
   ],
   "source": [
    "sum_text = sample_text_2\n",
    "\n",
    "a = Summarizer(sum_text, 0.6)\n",
    "words = a.word_sentence_tokenizer()\n",
    "words_ = words[1]\n",
    "sentence = words[0]\n",
    "token_scores = a.word_count_vec(words_)\n",
    "test = a.sentence_scoring(sentence, token_scores)\n",
    "\n",
    "fine = a.summary_sorting(test)\n",
    "final = string_synonym_swap(fine)\n",
    "\n",
    "# print(len(fine))\n",
    "# print(len(sample_text_2))\n",
    "print(f'The topic of this body of text is \"{a.text_topic}\".', '\\n')\n",
    "print('Original text')\n",
    "print(sum_text)\n",
    "print('\\n Length of original text: ', len(sum_text))\n",
    "print('\\n Proper summay \\n')\n",
    "print(final)\n",
    "print('length of summary: ', len(final))\n",
    "\n",
    "# how to print the topic\n",
    "# print(a.text_topic)#####################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "698943654ed90e0d601c73b15b591a66035d577c3c6badc918040a9e516c87b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
