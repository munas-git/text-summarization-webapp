{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from string import punctuation\n",
    "punctuation = punctuation + '’'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"The concept of leadership can be traced back to the very beginning of time in the garden of Eden where the first man, Adam had dominion over every living thing in the garden. Since then, kings have begun to appear. In every gathering, a king was appointed at every rally. Leaders were usually appointed from birth or from God’s instruction. In the Middle Ages, leaders were authoritarian, intimidating, fearful, and rare. As a result of the Renaissance, leadership has moved from the kings alone to parliament which consisted of simple men. This left a question, where did the authority come from? Isn't it from God? Jean-Jacques in 1762 made us know Authority comes from people who give up their personal freedom for their safety and security. Anxiety, robbery, murder was the order of the day for leadership in the Middle Ages. Fear and obedience were planted in the hearts of people between 500 AD and 1300 AD.19th and 20th Century Leadership: The Beginning of the Testimony of the Great Leaders That Emerged Leaders such as Abraham Lincoln of the United States, Giuseppe Mazzini of Italy, Kaiser Wilhelm II of Germany. Scholars have begun to pay more attention to leadership as theories were forming. However, in the 21st century, the emergence of information and communication Technology further evolved the concept of leadership as it provided a platform for greater inclusion in leadership, decision making and planning through globalization.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarizer():\n",
    "    '''\n",
    "    Class containing functions to clean, format and summarize text\n",
    "    > self:text, type - string\n",
    "    > self:churn_level float specifying percentage of original content to capture\n",
    "    '''\n",
    "\n",
    "\n",
    "    def __init__ (self, text, churn_level):\n",
    "        self.text = text\n",
    "        self.churn_level = float(churn_level)\n",
    "\n",
    "    \n",
    "    def word_sentence_tokenizer(self):\n",
    "        \"\"\" \n",
    "        This function breaks text into word and sentence tokens\n",
    "        Parameters:\n",
    "\n",
    "        > self:text, type -string\n",
    "        > self:churn_level float specifying percentage of original content to capture\n",
    "\n",
    "        return:\n",
    "        (sent_tokens, word_tokens) : Tuple containing sentences (sentence tokens) and\n",
    "        texts (text tokens) contained in text provided\n",
    "        \"\"\"\n",
    "\n",
    "        sent_tokens = sent_tokenize(self.text, 'english')\n",
    "        word_tokens = word_tokenize(self.text, 'english')\n",
    "        return(sent_tokens, word_tokens)\n",
    "\n",
    "    \n",
    "    def word_count_vec(self, word_tokens):\n",
    "        '''\n",
    "         This function produces a dictionary containing the normalized scores of each word tokens in a list\n",
    "         \n",
    "         Parameters:\n",
    "         > word_tokens = [] # List of words\n",
    "         \n",
    "         return:\n",
    "         word_frequency_scores : Dictionary of word tokens and their normalized scores\n",
    "        '''\n",
    "        clean_words = []\n",
    "        word_frequency_scores = {}\n",
    "\n",
    "        # Looping through to calculate word frequencies\n",
    "        for word in word_tokens:\n",
    "            if word.lower() not in stop_words:\n",
    "                if word not in punctuation:\n",
    "                    clean_words.append(word)\n",
    "                    if word not in word_frequency_scores:\n",
    "                        word_frequency_scores[word] = 1\n",
    "                    else:\n",
    "                        word_frequency_scores[word] += 1\n",
    "        \n",
    "        # Looping through to normalize word_frequency_scores using linear / minmax scaler\n",
    "        max_frequency = max(word_frequency_scores.values())\n",
    "        min_frequency = min(word_frequency_scores.values())\n",
    "        for word in word_frequency_scores.keys():\n",
    "            word_frequency_scores[word] = (word_frequency_scores[word] - min_frequency) / (max_frequency - min_frequency)\n",
    "        return(word_frequency_scores)\n",
    "    \n",
    "\n",
    "    def sentence_scoring(self, sentence_tokens, word_frequency_scores):\n",
    "        '''\n",
    "        This function calculates scores for each sentence and returns a dictionary containing sentence, score and order.\n",
    "        \n",
    "        Parameters:\n",
    "        > sentence_tokens: List containing sentence tokens\n",
    "        > word_frequency_scores: Dictionary containing word tokens and their (normalized) scores\n",
    "\n",
    "        return:\n",
    "        sentence_scores : Dictionary of sentences and their scores.\n",
    "\n",
    "        '''\n",
    "        sentence_scores = {}\n",
    "        for sentence in sentence_tokens:\n",
    "            for word in word_tokenize(sentence, 'english'):\n",
    "                if word.lower() in word_frequency_scores.keys():\n",
    "                    if sentence not in sentence_scores.keys():\n",
    "                        sentence_scores[sentence] = word_frequency_scores[word.lower()]\n",
    "                    else:\n",
    "                        sentence_scores[sentence] += word_frequency_scores[word.lower()]\n",
    "        return(sentence_scores)\n",
    "\n",
    "        \n",
    "    def summary_sorting(self, sentence_scores):\n",
    "        '''\n",
    "        This function selects the top n sentences based on the sentence scores\n",
    "        then organizes the final sentence in order of they appear in original text\n",
    "\n",
    "        Parameters:\n",
    "        self:churn_level - percentage of original content to capture\n",
    "        sentence_scores - Dictionary containing sentences and their scores.\n",
    "\n",
    "        return:\n",
    "        final_summary : String of final / formatted summary output.\n",
    "        '''\n",
    "\n",
    "        order_sorted_sentences = []\n",
    "        score_sorted_sentences = []\n",
    "        sentence_score_order_tuples = []\n",
    "\n",
    "        # multiplying churn level by number of sentences then converting to integer \n",
    "        top_n_sentences = int(self.churn_level * len(sentence_scores.keys()))\n",
    "\n",
    "        order = 1\n",
    "        # sort all sentences in descending order of their sentence_score values\n",
    "        for sentence, score in sentence_scores.items():\n",
    "            sentence_score_order_tuples.append((sentence, score, order))\n",
    "            order += 1\n",
    "        score_sorted_sentences = sorted(sentence_score_order_tuples, key=lambda tup: tup[1], reverse=True)\n",
    "        # Slicing from first to top_n_sentences and appending result to produce final summary.\n",
    "        top_n_slice = score_sorted_sentences[0:top_n_sentences]\n",
    "        order_sorted_sentences = sorted(top_n_slice, key=lambda tup: tup[2], reverse=False)\n",
    "        final_summary_list = [sentence[0] for sentence in order_sorted_sentences]\n",
    "        final_summary = ' '.join(final_summary_list)\n",
    "        return(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Summarizer(sample_text, 0.4)\n",
    "# words = a.word_sentence_tokenizer()\n",
    "# words_ = words[1]\n",
    "# sentence = words[0]\n",
    "# token_scores = a.word_count_vec(words_)\n",
    "# test = a.sentence_scoring(sentence, token_scores)\n",
    "\n",
    "# fine = a.summary_sorting(test)\n",
    "# print(fine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "698943654ed90e0d601c73b15b591a66035d577c3c6badc918040a9e516c87b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
